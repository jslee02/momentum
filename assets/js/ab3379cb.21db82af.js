"use strict";(self.webpackChunkstaticdocs_starter=self.webpackChunkstaticdocs_starter||[]).push([[8295],{23291:(e,r,s)=>{s.r(r),s.d(r,{assets:()=>c,contentTitle:()=>t,default:()=>m,frontMatter:()=>o,metadata:()=>n,toc:()=>l});var i=s(74848),a=s(28453);const o={sidebar_position:2},t="Process Markers",n={id:"examples/process_markers",title:"Process Markers",description:"Optical Marker based Body Tracking",source:"@site/docs/03_examples/02_process_markers.md",sourceDirName:"03_examples",slug:"/examples/process_markers",permalink:"/momentum/docs/examples/process_markers",draft:!1,unlisted:!1,editUrl:"https://github.com/facebookresearch/momentum/edit/main/momentum/website/docs/03_examples/02_process_markers.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"Viewers",permalink:"/momentum/docs/examples/viewers"},next:{title:"Convert Model",permalink:"/momentum/docs/examples/convert_model"}},c={},l=[{value:"Optical Marker based Body Tracking",id:"optical-marker-based-body-tracking",level:2},{value:"Example use cases",id:"example-use-cases",level:2},{value:"Track a marker sequence without a calibrated model.",id:"track-a-marker-sequence-without-a-calibrated-model",level:2},{value:"Track a marker sequence with a calibrated model.",id:"track-a-marker-sequence-with-a-calibrated-model",level:2}];function d(e){const r={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",header:"header",p:"p",pre:"pre",...(0,a.R)(),...e.components},{FbInternalOnly:s,OssOnly:o}=r;return s||p("FbInternalOnly",!0),o||p("OssOnly",!0),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(r.header,{children:(0,i.jsx)(r.h1,{id:"process-markers",children:"Process Markers"})}),"\n",(0,i.jsx)(r.h2,{id:"optical-marker-based-body-tracking",children:"Optical Marker based Body Tracking"}),"\n",(0,i.jsxs)(r.p,{children:["This project provides a set of core functions to solve for body motions based on optical marker inputs. It supports all PC OSes (untested on mobile).\nThe ",(0,i.jsx)(r.code,{children:"marker_tracker"})," lib contains core functionalities for downstream applications to build on. Demo applications are provided to show how they can be used to build your data processing pipeline. ",(0,i.jsx)(r.code,{children:"process_markers_app"})," solves for body motion given an input marker sequence, with or without an existing calibrated skeleton. ",(0,i.jsx)(r.code,{children:"refine_motion"})," runs smoothing as a post process to fill in missing data from input. They can be used to batch process mocap data in a python script."]}),"\n",(0,i.jsx)(r.admonition,{type:"info",children:(0,i.jsxs)(r.p,{children:["The Momentum ecosystem implicitly operates in ",(0,i.jsx)(r.em,{children:"centimeter"}),". If you are working with c3d files, we will do the unit conversion based on the stored unit on file. However, if you are using our API with your own data, make sure to convert them into cm. We also assume a Y-up coordinate system, which is not the industry convention (i.e., Z-up)."]})}),"\n",(0,i.jsx)(r.h2,{id:"example-use-cases",children:"Example use cases"}),"\n",(0,i.jsxs)(r.p,{children:["Get the full list of options for each application with ",(0,i.jsx)(r.code,{children:"-h"})," or ",(0,i.jsx)(r.code,{children:"--help"})," argument. ",(0,i.jsx)(r.code,{children:"02_01.c3d"})," is an example input file used by the default config files. Note that a config file can be used together with command line options. The command line overwrites values in the config file."]}),"\n",(0,i.jsx)(r.h2,{id:"track-a-marker-sequence-without-a-calibrated-model",children:"Track a marker sequence without a calibrated model."}),"\n",(0,i.jsxs)(r.p,{children:["The first step in tracking a marker file is to calibrate the subject's proportions and the markers' placement. It requires a ",(0,i.jsx)(r.code,{children:".locators"})," file that defines a template of marker layout on the body. We have a template file with common layouts from Vicon and OptiTrack. There is usually a Range-of-Motion (ROM) sequence captured for this calibration purpose."]}),"\n",(0,i.jsx)(r.p,{children:"Use a config file:"}),"\n",(0,i.jsx)(s,{children:(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{children:"buck2 run @arvr/mode/win/opt :process_markers_app -- -c process_markers_calib.config\n"})})}),"\n",(0,i.jsx)(o,{children:(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{children:"pixi run process_markers -c process_markers_calib.config\n"})})}),"\n",(0,i.jsxs)(r.p,{children:["Setting the ",(0,i.jsx)(r.code,{children:"calibrate"})," option to true will first calibrate the skeleton and the marker layout, then use the calibrated model for motion tracking."]}),"\n",(0,i.jsx)(s,{children:(0,i.jsxs)(r.p,{children:["The official template models are in ",(0,i.jsx)(r.a,{href:"https://www.internalfb.com/code/fbsource/arvr/libraries/momentum/models/",children:(0,i.jsx)(r.code,{children:"momentum/models"})}),"."]})}),"\n",(0,i.jsx)(r.h2,{id:"track-a-marker-sequence-with-a-calibrated-model",children:"Track a marker sequence with a calibrated model."}),"\n",(0,i.jsxs)(r.p,{children:["The tracking result from the above calibration step contains the calibrated model, and it can then be used to track other motion data from the same subject, without running the calibration step again. We currently only support saving/loading calibrated models in ",(0,i.jsx)(r.code,{children:".glb"})," format."]}),"\n",(0,i.jsx)(r.p,{children:"Use a config file:"}),"\n",(0,i.jsx)(s,{children:(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{children:"buck2 run @arvr/mode/win/opt :process_markers_app -- -c process_markers_tracking.config\n"})})}),"\n",(0,i.jsx)(o,{children:(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{children:"pixi run process_markers -c process_markers_tracking.config\n"})})}),"\n",(0,i.jsx)(r.p,{children:"Use cli arguments:"}),"\n",(0,i.jsx)(s,{children:(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{children:"buck2 run :process_markers_app -- -i input.c3d -o tracked.glb --model calibrated_model.glb --calibrate false\n"})})}),"\n",(0,i.jsx)(o,{children:(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{children:"pixi run process_markers -i input.c3d -o tracked.glb --model calibrated_model.glb --calibrate false\n"})})})]})}function m(e={}){const{wrapper:r}={...(0,a.R)(),...e.components};return r?(0,i.jsx)(r,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}function p(e,r){throw new Error("Expected "+(r?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}}}]);